{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing_extensions import Literal\n",
    "from typing import Optional, List\n",
    "from Layer import Layer\n",
    "#from activation_functions import *\n",
    "\n",
    "\n",
    "class MLP(object):\n",
    "  # Multilayer Perceptron class\n",
    "\n",
    "  def __init__(self, \n",
    "    layers: List[Layer],\n",
    "    learning_rate: float = 0.1,\n",
    "    a_linear = Optional[float], \n",
    "    b_linear = Optional[float]):\n",
    "\n",
    "    self.layers = layers # List of layers\n",
    "    self.learning_rate = learning_rate # Learning rate\n",
    "    self.errors  = [] # List to store errors\n",
    "  \n",
    "  def forward(self, stimulus)->np.ndarray:\n",
    "    '''\n",
    "    Forward propagation\n",
    "    '''\n",
    "    for layer in self.layers:\n",
    "      print(\"is\")\n",
    "      stimulus = layer.forward(stimulus)\n",
    "    return stimulus\n",
    "\n",
    "\n",
    "  def backward(self,  y: np.ndarray)->None:\n",
    "    '''\n",
    "    Backward propagation\n",
    "    '''\n",
    "    local_gradient = y - self.layers[-1].output\n",
    "    for layer in reversed(self.layers):\n",
    "      print(\"local_gradient\", local_gradient.shape)\n",
    "      local_gradient = layer.backward(local_gradient)\n",
    "\n",
    "  def update_weights(self):\n",
    "    '''\n",
    "    Update weights\n",
    "    '''\n",
    "    for layer in self.layers:\n",
    "      layer.update(self.learning_rate)\n",
    "\n",
    "  def train(self, x: np.ndarray, y: np.ndarray, epochs: int):\n",
    "    '''\n",
    "    Train MLP\n",
    "    '''\n",
    "    for epoch in range(epochs):\n",
    "      y_output = self.forward(x)\n",
    "      error = abs(y - y_output)\n",
    "      self.backward(y)\n",
    "      self.update_weights()\n",
    "\n",
    "      if epoch%100 == 0:\n",
    "        print(\"Epoch: \", epoch, \"Error: \", np.mean(error))\n",
    "      self.errors.append(np.mean(error))\n",
    "\n",
    "  def get_gradients(self):\n",
    "    '''\n",
    "    Get gradients\n",
    "    '''\n",
    "    gradients = []\n",
    "    for layer in self.layers:\n",
    "      gradients.append(layer.weights_grad)\n",
    "    return gradients\n",
    "    \n",
    "  def predict(self, x):\n",
    "    y_output = self.forward(x)\n",
    "    return y_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Optional\n",
    "\n",
    "class Layer:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_size: np.ndarray, \n",
    "        output_size: np.ndarray, \n",
    "        activation: str,\n",
    "        a_linear: Optional[float] = 1.0,\n",
    "        b_linear: Optional[float] = 0,\n",
    "      ):\n",
    "        self.weights = np.random.rand(output_size, input_size)\n",
    "\n",
    "        self.stimulus = None\n",
    "        self.local_field = None\n",
    "        self.output = None\n",
    "\n",
    "        self.local_gradient = None\n",
    "        self.weights_grad = None\n",
    "\n",
    "        self.activation = activation\n",
    "        self.a_linear = a_linear\n",
    "        self.b_linear = b_linear\n",
    "\n",
    "    def forward(self, inputs: np.ndarray) -> np.ndarray:\n",
    "        self.stimulus = inputs\n",
    "        self.local_field = np.matmul(self.weights, self.stimulus)\n",
    "        self.output = self.phi(self.local_field)\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, previous_gradient: np.ndarray) -> np.ndarray:\n",
    "        print(\"is\", previous_gradient.shape, self.local_field.shape,self.compute_derivative(self.local_field).shape)\n",
    "        self.local_gradient = np.multiply(\n",
    "            previous_gradient, self.compute_derivative(self.local_field)\n",
    "        )\n",
    "        print(\"local_gradient shape\", self.local_gradient.shape, self.stimulus.T.shape)\n",
    "        self.weights_grad = np.matmul(self.local_gradient, self.stimulus.T)\n",
    "        print(\"weights_grad shape\", self.weights.shape,self.weights_grad.shape)\n",
    "        self.weights_grad = np.matmul(self.weights.T, self.weights_grad)\n",
    "        return self.local_gradient\n",
    "\n",
    "    def compute_derivative(self, v:np.ndarray) -> np.ndarray:\n",
    "        if(self.activation == \"Linear\"):\n",
    "          return np.zeros(v.shape)+1\n",
    "        elif(self.activation == \"Sigmoid\"):\n",
    "            return self.phi(v)*\\\n",
    "            (1-self.phi(v))\n",
    "        elif(self.activation == \"Tanh\"):\n",
    "            return 1 - self.phi(v)**2\n",
    "\n",
    "    def update(self, learning_rate: float) -> None:\n",
    "        self.weights = self.weights - learning_rate * self.weights_grad\n",
    "\n",
    "    def phi(self, v: np.ndarray) -> np.ndarray:\n",
    "        if(self.activation == \"Linear\"):\n",
    "          return self.a_linear*v + self.b_linear\n",
    "        elif(self.activation == \"Sigmoid\"):\n",
    "            return 1/(1+np.exp(-v))\n",
    "        elif(self.activation == \"Tanh\"):\n",
    "            return np.tanh(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing_extensions import Literal\n",
    "from typing import Optional, List\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "X_iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n",
      "is\n",
      "local_gradient (1, 150)\n",
      "is (1, 150) (1, 150) (1, 150)\n",
      "local_gradient shape (1, 150) (150, 2)\n",
      "weights_grad shape (1, 2) (1, 2)\n",
      "local_gradient (2, 2)\n",
      "is (2, 2) (2, 150) (2, 150)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,2) (2,150) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\1862761844.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_iris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_iris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\699032674.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x, y, epochs)\u001b[0m\n\u001b[0;32m     53\u001b[0m       \u001b[0my_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m       \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\699032674.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m       \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"local_gradient\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_gradient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m       \u001b[0mlocal_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_gradient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mupdate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\2739354364.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, previous_gradient)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"is\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_gradient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_field\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_field\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         self.local_gradient = np.multiply(\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mprevious_gradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_field\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         )\n\u001b[0;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"local_gradient shape\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_gradient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstimulus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,2) (2,150) "
     ]
    }
   ],
   "source": [
    "model = MLP(layers = [Layer(4, 2, activation = 'Sigmoid'),Layer(2, 1, activation = 'Sigmoid')], learning_rate = 0.1)\n",
    "model.train(X_iris.T, y_iris.T, epochs = 1000)\n",
    "grads = model.get_gradients()\n",
    "print(len(grads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_iris.T)\n",
    "error = np.mean(np.abs(predictions-y_iris.T))\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('musical_taste')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "054c0b359d417d33b5fbe9b95cb8d7311abeb8070f400d95aa11f47a6d7aacca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
