# Supervising My Musical Taste :drum:
 
Music plays a great role in peoples life and influences different parts of the daily routine such as the mood or the performance in sports, study, work, etc. Therefore, in the contemporary era of information many researchers have dedicated their work to improving music recommendation systems that enable people to find new music or allow artists to reach a wider public.

This work emerges from the hypothesis that not all humans are sensitive to the same features and that the first question should be instead, what makes us like or dislike music?

Therefore, I decided to study the feature spaces generated by the songs I like the most and the ones I hate the most looking forward to detect which aspect of music is the one I am more sensitive to. Is it the timbre? the rhythm? a combination of both?. Although I am sure the context might influence a lot the emotions perceived in a musical piece, there is a pattern why friends and family tend to give accurate recommendations that lacks of any biases based on the context. This means they are capable of learning your musical taste, but are probably not able to describe it.

The aim of this work is precisely trying to detect the patterns that represent my musical taste in a supervised manner. Taking an accurate sampling strategy, using the appropriate learning considerations I want to separate songs into two distinct classes, songs I like and songs I would dislike.

## Installation instructions :computer:
To replicate the results follow this steps:

Install the requirements list either with pip
```
pip install -r requirements.txt
```
or create an environment
```
conda create --name musical_taste --file requirements.txt
```
Then activate your environment
```
conda activate musical_taste
```

## Feature extraction :musical_note:
My dataset is a combination of two playlists\
[:cd: Songs I love](https://open.spotify.com/playlist/0c5l61Nfs7Ie0TrJ5NP5JJ?si=a7bdd16bc35c44b1)\
[:cd: Songs I hate](https://open.spotify.com/playlist/37i9dQZF1EUMDoJuT8yJsl?si=3c0fe5d717994539)

You can build your own dataset and create a folder Dataset with two subfolders named Like and Dislike.
The first step is making all songs to have the same length
```
python .\data_processing.py 
```
To extract the features run:
```
python .\feature_extraction.py 
```

For my experiment, all the features were stored as a pickle file
[Dataset :musical_score:](dataset_features.pckl)

The results with learning machines can be found at the following notebook :
[Notebook  :musical_keyboard:](supervising_my_musical_taste.ipynb)

## Multilayer Perceptron (MLP) :musical_note:
In order to supervise the learning process of my musical taste I used a self created 
[Multilayer Perceptron ](https://github.com/IsitaRex/Supervising-My-Musical-Taste/blob/810f596b126773d3c525ab098154cfee992d2f46/Multilayer%20Perceptron/MLP.py)
which receives a list of 
[layers](https://github.com/IsitaRex/Supervising-My-Musical-Taste/blob/810f596b126773d3c525ab098154cfee992d2f46/Multilayer%20Perceptron/Layer.py) and a learning rate.

### Example model
To create a MLP with one hidden layer, 80 inputs, one output, Sigmoid activation functions and a learning rate of 0.1 use:
```
model = MLP(layers = [Layer(80, 1, activation = 'Sigmoid'),Layer(1, 1, activation = 'Sigmoid'),Layer(1, 1, activation = 'Sigmoid')], learning_rate = 0.1)
```
To train the model
```
model.train(X_train.T, y_train.T, epochs = 50)
```
